## 数据库
### 数据库交互
- pymysql
  - 安装包：`pip install pymysql`
```python
#!/usr/bin/env python
#-*- coding: utf-8 -*-
#FILE: test_pymysql.py
#CREATE_TIME: 2022-07-15
#AUTHOR: Sancho

import pymysql

# 连接数据库
conn = pymysql.connect(host="数据库地址",
                       user="用户名",
                       passwd="密码",
                       database="数据库名",
                       charset="utf-8")
cursor = conn.cursor()  # 实例化游标

# 增加单条
sql = 'insert into userinfo(user,age) values(%s,%s);'  # 待执行的SQL语句
cursor.execute(sql, ['Sancho', '23'])  # 执行一条
conn.commit()  # 提交更改
# 增加多条
data = [('Severin', '27'), ('Zuhayr', '25'), ('Hain', '22')]
cursor.executemany(sql, data)  # 执行多条
conn.commit()

# 删除
sql = "delete from userinfo where user=%s;"
name = "Zuhayr"
cursor.execute(sql, [name])
conn.commit()

# 更新
sql = "update userinfo set age=%s where user=%s;"
cursor.execute(sql, ["23", "Hain"])
conn.commit()

# 查询
sql = 'select user,age from userinfo;'
cursor.execute(sql)
ret = cursor.fetchmany(2)  # 指定查询数量
cursor.scroll(1, mode="absolute")  # 移动一步，按绝对位置查询;mode="relative"按相对位置移动
print(ret)
# 查询最后一条ID
print(cursor.lastrowid)

# 回滚
sql = "insert into userinfo (user, age) values (%s, %s);"
try:
    cursor.execute(sql, ["25", "Error"])  # 此行错误
    conn.commit()
except Exception as e:
    print(str(e))
    conn.rollback()  # 有异常就回滚

# 关闭光标对象
cursor.close()
# 关闭数据库连接
conn.close()
```
- redis
  - 安装包：`pip install pymysql`
```python
#!/usr/bin/env python
#-*- coding: utf-8 -*-
#FILE: test_redis.py
#CREATE_TIME: 2022-07-15
#AUTHOR: Sancho

import redis

# 连接数据库
# 普通连接
redis_conn = redis.Redis(host='数据库地址', port=6379, password='密码',
                         db=0)  # 端口默认6379，第0个db
# 连接池方式
# redis_pool = redis.ConnectionPool(host='数据库地址', port= 6379, password= '密码', db= 0)
# redis_conn = redis.Redis(connection_pool= redis_pool)

# 设置（不存在则新建，存在则修改）
redis_conn.set('Sancho', '23')  # 设置单条
redis_conn.mset({'Severin': '27', 'Zuhayr': '25', 'Hain': '22'})  # 设置多条
# 列表
redis_conn.lpush('Zarten', 1, 2, 3, 4, 5)  # 依次向左添加为列表；.rpush()向右添加
redis_conn.lpushx('Zarten_1', '6')  # 依次向左添加为列表，键不存在则不添加；.rpushx()向右添加
redis_conn.lset('Zarten', 2, 'cc')  # 通过索引赋值
# 哈希
redis_conn.hset('Sancho', 'age', 23)  # 设置键值对
redis_conn.hmset('Sancho', {'sex': 1, 'age': '23'})  # 设置多个键值对
# 集合
redis_conn.sadd('Zarten', 'apple', 'a', 'b', 'c')  # 设置元素
# 有序集合
redis_conn.zadd('Zuhayr', 'a', 3, 'b', 4)  # 设置元素权重和值
# 位图
redis_conn.setbit(
    'Hain', 0,
    b'010100110110000101101110011000110110100001101111')  # 设置偏移和二进制值

# 获取
print(redis_conn.get('Sancho'))  # 获取单条
print(redis_conn.mget('Severin', 'Zuhayr', 'Hain'))  # 获取多条
# 列表
print(redis_conn.strlen('Sancho'))  # 获取值的长度
print(redis_conn.llen('Zarten'))  # 获取列表值的长度
print(redis_conn.lindex('Zarten', 2))  # 通过索引获取列表值
# 哈希
print(redis_conn.hget('Sancho', 'age'))  # 获取键值
print(redis_conn.hmget('Sancho', ['sex', 'age']))  # 获取多个键值对
print(redis_conn.hgetall('Sancho'))  # 获取所有键值对
print(redis_conn.hlen('Sancho'))  #获取键值对个数
print(redis_conn.hkeys('Sancho'))  # 获取所有键
print(redis_conn.hvals('Sancho'))  # 获取所有值
print(redis_conn.hexists('Sancho', 'age'))  # 检查是否存在键
# 集合
print(redis_conn.scard('Zarten'))  # 返回集合种元素的个数
print(redis_conn.smembers('Zarten'))  # 获取集合中所有元素
print(redis_conn.sismember('Zarten', 'appl'))  # 检查集合中是否包含元素
print(redis_conn.sdiff('Zarten', 'Sancho'))  # 获取差集
print(redis_conn.sinter('Zarten', 'Sancho'))  # 获取交集
print(redis_conn.sunion('Zarten', 'Fruit'))  # 返回并集
# 有序集合
print(redis_conn.zcard('Zuhayr'))  # 返回有序集合的元素个数
print(redis_conn.zcount('Zuhayr', 3, 5))  # 返回有序集合中权重范围内的元素个数
print(redis_conn.zscore('Zuhayr', 'a'))  # 返回指定值的权重
print(redis_conn.zrank('Zarten', 'b'))  # 返回权重从小到大排列的元素；.zrevrank()从大到小
# 位图
print(redis_conn.getbit('Hain', 0))  # 返回指定偏移量的值

# 修改
print(redis_conn.getset('Sancho', '22'))  # 返回原值，并设置新值
print(redis_conn.append('Sancho', '0'))  # 追加（不存在则新建），返回值的长度
# 列表
redis_conn.linsert('Zarten', 'AFTER', 6, 'b')  # 在列表中插入新值，返回列表长度
# 集合
redis_conn.sdiffstore('Severin', 'Zarten', 'Sancho')  # 将差集保存到另一个集合
redis_conn.sinterstore('Severin', 'Zarten', 'Sancho')  # 将交集保存到另一个集合
redis_conn.sunionstore('Severin', 'Zarten', 'Sancho')  # 将并集保存到另一个集合
# 有序结合
redis_conn.zincrby('Zuhayr', 'a', -1)  # 修改元素的权重

# 删除
# 列表
redis_conn.lpop('Zarten')  # 删除列表左边的值；.rpop()删除右边
# 哈希
redis_conn.hdel('Sancho', 'age')  # 删除键值对
# 集合
redis_conn.srem('Zarten', 'c', 'a')  # 删除元素
# 有序结合
redis_conn.zrem('Zuhayr', 'a', 'b')  # 删除元素
redis_conn.zremrangebyrank('Zuhayr', 1, 3)  # 删除下标范围内的元素
redis_conn.zremrangebyscore('Zuhayr', 1, 3)  # 删除权重范围内的元素

# 全局函数
redis_conn.delete('Zaten', 'Hain')  # 删除键
redis_conn.exists('Sancho')  # 检查键是否存在
redis_conn.rename('Sancho', 'Lion')  # 更改键名
redis_conn.move('Sancho', 12)  # 移动键到其它数据库
redis_conn.type('Sancho')  # 查看某个键的数据结构
```
- pymongo
  - 安装包：`pip install pymongo`
```python
#!/usr/bin/env python
#-*- coding: utf-8 -*-
#FILE: test_mongodb.py
#CREATE_TIME: 2022-07-15
#AUTHOR: Sancho

import pymongo

# 连接数据库
myclient = pymongo.MongoClient("mongodb://数据库地址:密码@端口号/")
mydb = myclient["ts001"]
# 创建集合
mycol = mydb["sites"]  # 增加数据才算创建成功

# 增加文档
mycol.insert_one({"name": "Sancho", "age": "23"})  # 增加一条数据，返回文档id
mycol.insert_many([{
    "name": "Sancho",
    "age": "23"
}, {
    "name": "Severin",
    "age": "27"
}])  # 增加多条数据，返回对应多条文档id
mycol.insert_many([{
    "_id": "1",
    "name": "Sancho",
    "age": "23"
}, {
    "_id": "2",
    "name": "Severin",
    "age": "27"
}])  # 增加多条数据，并指定id

# 查询文档
[print(i) for i in mycol.find()]  # 查询集合种所有数据
[print(i) for i in mycol.find({}, {"_id": 1, "name": 1})]  #查询集合种所有数据并按所需字段返回
[print(i) for i in mycol.find({"name": "Sancho"})]  # 查询指定条件的数据
[print(i) for i in mycol.find().sort("age", 1)]  # 对文档进行排序输出,1为升序，-1为倒序
[print(i) for i in mycol.find({"age": {"$gt": "18"}})]  # 高级查询，age大于18的数据
[print(i) for i in mycol.find({"name": {
    "$regex": "^S"
}})]  # 正则查询，name的值为S开头的数据

# 修改文档
mycol.update_one({"age": "23"}, {"$set": {"age": "22"}})  # 更新一条文档
mycol.update_many({"age": "23"}, {"$set": {"age": "22"}})  # 更新全部文档

# 删除文档
mycol.delete_one({"name": "Severin"})  # 删除一条数据
mycol.delete_many({"name": {"$regex": "^S"}})  # 删除多条数据
mycol.delete_many({})  # 删除所有数据
mycol.drop()  # 删除集合
```
### 网址数据存储
```python
#!/usr/bin/env python
#-*- coding: utf-8 -*-
#FILE: test_urldb.py
#CREATE_TIME: 2022-07-14
#AUTHOR: Sancho
"""
网址数据库实现
!需要linux
TODO:更换成其它数据库
"""

import leveldb


class UrlDB:
    """
    使用数据库储存已完成的url
    """
    status_failure = b'0'
    status_success = b'1'

    def __init__(self, db_name):
        self.name = db_name + '.urldb'
        self.db = leveldb.LevelDB(self.name) # 连接数据库

    def set_success(self, url):
        """添加成功的数据"""
        if isinstance(url, str): # 判断数据是否是字符串
            url = url.encode('utf8')
        try:
            self.db.Put(url, self.status_success) # 尝试写入数据
            s = True
        except:
            s = False
        return s

    def set_failure(self, url):
        """添加失败的数据"""
        if isinstance(url, str):
            url = url.encode('utf8')
        try:
            self.db.Put(url, self.status_failure)
            s = True
        except:
            s = False
        return s

    def has(self, url):
        """判断数据是否已存在数据库"""
        if isinstance(url, str):
            url = url.encode('utf8')
        try:
            attr = self.db.Get(url)
            return attr
        except:
            pass
        return False
```
### 网址池
```python
#!/usr/bin/env python
#-*- coding: utf-8 -*-
#FILE: test_urlpool.py
#CREATE_TIME: 2022-07-14
#AUTHOR: Sancho
"""
网址池实现
!需要linux
TODO:更换成其它数据库
TODO:替换urllib.parse代码
"""

import pickle
import leveldb
import time
import urllib.parse as urlparse


class UrlPool:
    '''
    用于管理url的网址池
    '''

    def __init__(self, pool_name):
        self.name = pool_name
        self.db = UrlDB(pool_name) # 载入网址数据库

        self.waiting = {}  # {host: set([urls]), } 按host分组，记录等待下载的URL
        self.pending = {}  # {url: pended_time, } 记录已被取出（self.pop()）但还未被更新状态（正在下载）的URL
        self.failure = {}  # {url: times,} 记录失败的URL的次数
        self.failure_threshold = 3 # 允许的最大失败次数
        self.pending_threshold = 10  # pending的最大时间，过期要重新下载
        self.waiting_count = 0  # self.waiting 字典里面的url的个数
        self.max_hosts = ['', 0]  # [host: url_count] 目前pool中url最多的host及其url数量
        self.hub_pool = {}  # {url: last_query_time, }  存放hub url（首页的链接）
        self.hub_refresh_span = 0 # 爬取的时间频率
        self.load_cache() # 读取上次未完成抓取网址的数据

    def __del__(self):
        """退出时自动调用写入缓存"""
        self.dump_cache()

    def load_cache(self,):
        """读取上次未完成抓取网址的数据"""
        path = self.name + '.pkl'
        try:
            with open(path, 'rb') as f:
                self.waiting = pickle.load(f) # 读到内存
            cc = [len(v) for k, v in self.waiting.items()] # 数据字段计数
            print('加载到网址池的网址:', sum(cc))
        except:
            pass

    def dump_cache(self):
        """写入缓存"""
        path = self.name + '.pkl'
        try:
            with open(path, 'wb') as f:
                pickle.dump(self.waiting, f) # 将未完成抓取的网址，序列化写入硬盘
            print('self.waiting saved!')
        except:
            pass

    def set_hubs(self, urls, hub_refresh_span):
        """加载首页中的链接到网址池"""
        self.hub_refresh_span = hub_refresh_span
        self.hub_pool = {}
        for url in urls:
            self.hub_pool[url] = 0

    def set_status(self, url, status_code):
        """访问链接并设置状态"""
        if url in self.pending:
            self.pending.pop(url) # 取出已下载的、待更新的url

        if status_code == 200:
            self.db.set_success(url) # 写入到成功的网址池
            return
        if status_code == 404:
            self.db.set_failure(url) # （地址不存在）写入到失败的网址池
            return
        if url in self.failure: # 其它状态时判断是否已经在失败的网址池中
            self.failure[url] += 1 # 记录失败次数+1
            if self.failure[url] > self.failure_threshold: # 判断失败次数是否超过上限
                self.db.set_failure(url) # 从数据库中设置失败状态
                self.failure.pop(url) # 从失败的网址池中销毁
            else: # 没有达到失败上限
                self.add(url) # 重新加载（放入self.waittig）
        else: # 第一次失败
            self.failure[url] = 1
            self.add(url) # 重新加载（放入self.waittig）

    def push_to_pool(self, url):
        """将url按host分组放入self.waiting"""
        host = urlparse.urlparse(url).netloc # 解析到主机地址
        if not host or '.' not in host: # 判断主机地址是否合法
            print('地址错误:', url, ', len of ur:', len(url))
            return False
        if host in self.waiting: # 判断主机地址是否已被记录
            if url in self.waiting[host]: # 判断链接是否已经在待下载池中
                return True
            self.waiting[host].add(url) # 添加链接到待下载池中
            if len(self.waiting[host]) > self.max_hosts[1]: # 判断host下的链接是否是最多的
                self.max_hosts[1] = len(self.waiting[host]) # 刷新host的最多数量
                self.max_hosts[0] = host
        else: # 如果不存在待下载队列（新链接）
            self.waiting[host] = set([url]) # 加入待下载队列
        self.waiting_count += 1 # 计数器+1
        return True

    def add(self, url, always=False):
        """将链接添加到网址池"""
        if always: # 强制放入待下载队列
            return self.push_to_pool(url)
        pended_time = self.pending.get(url, 0) # 查看上次下载的时间
        if time.time() - pended_time < self.pending_threshold: # 是否在刷新间隔
            print('正在下载:', url)
            return
        if self.db.has(url): # 链接是否在数据库
            return
        if pended_time: # 超过刷新间隔
            self.pending.pop(url) # 弹出
        return self.push_to_pool(url) # 放入self.waiting

    def addmany(self, urls, always=False):
        """将多个链接添加到网址池"""
        if isinstance(urls, str): # 判断是否是字符串类型
            print('urls是字符串，请传入多个链接的可迭代对象！', urls)
            self.add(urls, always)
        else:
            for url in urls:
                self.add(url, always) # 遍历将url添加到网址池

    def pop(self, count, hub_percent=50):
        """
        弹出链接进入下载
        count:需要弹出的链接个数（并发）
        hub_percent:弹出的链接中hub_url的占比
        """
        print('\n\tmax of host:', self.max_hosts)

        # 取出的url有两种类型：hub=1, 普通=0
        url_attr_url = 0 # 0表示普通url
        url_attr_hub = 1 # 1表示hub_url

        # 1. 首先取出hub，保证获取hub里面的最新url.
        hubs = {}
        hub_count = count * hub_percent // 100 # 计算需要弹出的hub_url个数
        for hub in self.hub_pool:
            span = time.time() - self.hub_pool[hub] # 计算到上次弹出时的时间差
            if span < self.hub_refresh_span: # 判断时间差是否在刷新间隔
                continue
            hubs[hub] = url_attr_hub 
            self.hub_pool[hub] = time.time() # 更新时间戳
            if len(hubs) >= hub_count: # 计算弹出个数
                break

        # 2. 再取出普通url
        left_count = count - len(hubs) # 计算需要弹出的普通url个数
        urls = {}
        for host in self.waiting: # 遍历待下载的队列
            if not self.waiting[host]: # 判断当前host下是否没有链接待爬取
                continue
            url = self.waiting[host].pop() # 弹出url
            urls[url] = url_attr_url # 标记为普通url
            self.pending[url] = time.time() # 更新时间戳
            if self.max_hosts[0] == host: # 判断是否是最多链接数的host
                self.max_hosts[1] -= 1
            if len(urls) >= left_count: # 达到需要弹出的数量
                break
        self.waiting_count -= len(urls) # 更新计数器
        print('To pop:%s, hubs: %s, urls: %s, hosts:%s' % (count, len(hubs), len(urls), len(self.waiting)))
        urls.update(hubs) # 合并urls和hubs两个字典
        return urls

    def size(self,):
        """返回链接数"""
        return self.waiting_count

    def empty(self,):
        """查看待爬取的地址池是否为空"""
        return self.waiting_count == 0
```
